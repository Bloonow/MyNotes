[toc]

# 补充积分

欧拉积分：
$$
\int_0^{+\infty}x^ne^{-x}dx=n!
$$
高斯函数积分：
$$
\int_{-\infty}^{+\infty}e^{-(\frac{x-\mu}{A})^2}dx=A\sqrt{\pi}
$$

# 一、随机事件及其概率

## （一）随机事件及其关系和运算

### 1. 定义

对随机现象进行观察或实验称为随机试验，简称试验，记为$E$；随机试验的每一可能结果称为样本点，记为$\omega$，所有样本点全体组成的集合称为样本空间，记为$\Omega$；样本空间的子集称为随机事件，简称事件；将$\Omega$看成一事件，称为必然事件，将不包含任何样本点的空集$\varnothing$看成一个事件，称为不可能事件。

### 2. 事件的关系及运算

事件的交（积）。如果事件$A$与事件$B$同时发生，则称这样的一个事件为事件$A$与事件$B$的交或者积，记为$A\cap B$或AB。

事件的并（和）。如果事件$A$与事件$B$至少有一个发生，则称这样的一个事件为事件$A$与事件$B$的并或者和，记为$A\cup B$。

包含关系。如果事件$A$的发生必然导致事件$B$发生，则称事件$B$包含事件$A$，或事件$A$包含于事件$B$，记为$B\supset A$或$A\subset B$。

相等（等价）关系。如果$B\supset A$和$A\subset B$同时成立，则称事件$A$与事件$B$相等，记为$A=B$。

互斥（互不相容）关系。如果事件$A$与事件$B$的关系是$AB=\varnothing$，即$A$与$B$不能同时发生，则称事件$A$和事件$B$互斥或互不相容。

对立（互逆）关系。如果事件$A$与事件$B$有且仅有一个发生，即同时成立$A\cup B=\Omega$，且$AB=\varnothing$，则称事件$A$与事件$B$为对立事件或互逆事件，记为$\overline{A}=B$或$\overline{B}=A$。特别地，$A\overline{A}=\varnothing，A\cup\overline{A}=\Omega$。

事件的差。事件$A$发生而事件$B$不发生称为事件$A$与事件$B$的差，记为$A-B$，显然$A-B=A\overline{B}$。

交换律、结合律、分配率、德摩根对偶律。$\overline{A\cup B}=\overline{A}\cap\overline{B}，\overline{A\cap B}=\overline{A}\cup\overline{B}$。

## （二）概率的公理化

### 1. 定义

**定义**：设$E$是随机试验，$\Omega$是$E$的样本空间，对于随机试验$E$的每一个随机事件$A$都赋予一个实数，记为$P(A)$，称为事件$A$的概率，若它满足下列三个条件：

1. 非负性，对任意事件$A$，都有$P(A)\ge 0$；
2. 规范性，对必然事件$\Omega$，有$P(\Omega)=1$；
3. 可列可加性，事件$A_1,A_2,\cdots,A_n,\cdots$为互不相容事件，则$P(\sum\limits_{i=1}^\infty A_i)=\sum\limits_{i=1}^\infty P(A_i)$

上述定义称为**概率的公理化定义**。值得注意的是，若只给出概率的条件是得不出事件关系的结论的。

### 2. 性质

1. 不可能事件的概率为零，即$P(\varnothing)=0$
2. 有限可加性，若事件$A_1,A_2,\cdots,A_n,\cdots$为互不相容事件，则有$P(A_1+A_2+\cdots+A_n)=P(A_1)+P(A_2)+\cdots+P(A_n)$
3. 单调性与可减性，若$A\sub B$，则$P(A)\le P(B)$，且$P(B-A)=P(B)-P(AB)=P(B)-P(A)$
   - 有界性（推论），对任一事件$A$，有$0\le P(A)\le 1$
4. 逆事件的概率公式，$P(\overline A)=1-P(A)$
5. 减法公式，$P(B-A)=P(B)-P(AB)$
6. 加法公式，$P(A\cup B)=P(A)+P(B)-P(AB)$
   - 相容互斥原理（推论）。

## （三）条件概率

### 1. 定义与性质

**定义**：设$A,B$是同一随机试验$E$的两个事件，且$P(B)>0$，则称
$$
P(A|B) = \frac{P(AB)}{P(B)} = \frac{P(A,B)}{P(B)}
$$
为事件$A$在已知事件$B$发生后的**条件概率**，简称$A$关于$B$的条件概率。

计算条件概率一般有两种方法：

1. 在原样本空间$\Omega$中，分别计算$P(AB)$和$P(B)$，再利用定义求得。
2. 在缩减样本空间$\Omega_B=B$中计算事件$A$发生的概率，即$A$关于$B$的条件概率。

设$H,A,B,C$及$A_1,A_2,\cdots,A_n$是试验$E$的事件，且$P(H)>0$，则有

1. 非负性，任一事件$A$，有$P(A|H)\ge0$
2. 规范性，$P(\varnothing|H)=0,P(\Omega|H)=1,P(H|H)=1$
3. 逆事件条件概率，$P(\overline A|H)=1-P(A|H)$
4. 减法公式，$P((B-A)|H)=P(B|H)-P(AB|H)$
5. 加法公式，$P((A\cup B)|H)=P(A|H)+P(B|H)-P(AB|H)$

### 2. 乘法公式

设$A,B$是随机试验$E$的两个事件，且$P(B)>0$，根据条件概率的定义，若$P(B)>0$，则有
$$
P(AB)=P(A|B)\cdot P(B)
$$
同理，若$P(A)>0$，则有
$$
P(AB)=P(B|A)\cdot P(A)
$$
这两个等式称为概率的**乘法公式**。可以推广值任意有限个事件乘积的场合，例如设$A,B,C$为任意三个事件，若$P(AB)>0$，则有$P(ABC)=P(C|AB)\cdot P(B|A)\cdot P(A)$

一般地，设$A_1,A_2,\cdots,A_n$为任意$n$个事件，若有$P(A_1A_2\cdots A_n)>0$，则
$$
P(A_1A_2\cdots A_{n-1}A_n)=P(A_n|A_1A_2\cdots A_{n-1})\cdots P(A_3|A_1A_2)P(A_2|A_1)P(A_!)
$$

### 3. 全概率公式与贝叶斯公式

**定义**：设$\Omega$是随机试验$E$的样本空间，如果$E$中的事件$A_1,A_2,\cdots,A_n$满足$A_iA_j=\varnothing(i\ne j)$和$A_1\cup A_2\cup\cdots\cup A_n=\Omega$，则称$A_1,A_2,\cdots,A_n$是样本空间$\Omega$的一个划分（或分隔）。

**定理**（全概率公式）：设$A_1,A_2,\cdots,A_n$是样本空间$\Omega$的一个划分，且$P(A_i)>0,\ i=1,2,\cdots,n$，则对任一事件$B$，有
$$
P(B)=\sum_{i=1}^n[P(A_i)P(B|A_i)]
$$
**定理**（贝叶斯公式）：设$A_1,A_2,\cdots,A_n$是样本空间$\Omega$的一个划分，且$P(A_i)>0,\ i=1,2,\cdots,n$，则对任一事件$B$，若$P(B)>0$，则有
$$
P(A_k|B)=\frac{P(A_kB)}{P(B)}=\frac{P(B|A_k)P(A_k)}{\sum\limits_{i=1}^n[P(A_i)P(B|A_i)]} \qquad k=1,2,...,n
$$

## （四）事件的独立性

**定义**：设$A,B$是随机试验E的两个事件，若$P(AB)=P(A)P(B)$，则称事件$A$与$B$**相互独立**（或**统计独立**），简称$A$与$B$独立（垂直）。独立并不是说互斥，互斥是在样本点上定义的，独立是在概率上定义的。

**定理**：设$A,B$是随机试验E的两个事件，若$P(A)>0$，则事件$A$与$B$独立的充分必要条件是$P(B|A)=P(B)$；若$P(B)>0$，则事件$A$与$B$独立的充要条件是$P(A|B)=P(A)$。

**定理**：若事件$A$与$B$相互独立，则$\{\overline A,B\},\{A,\overline B\},\{\overline A,\overline B\}$也相互独立。

**定义**：对于三个事件$A,B,C$，如果
$$
\begin{cases}
P(AB)=P(A)P(B) \\
P(AC)=P(A)P(C) \\
P(BC)=P(B)P(C) \\
P(ABC)=P(A)P(B)P(C)
\end{cases}
$$
成立，则称事件$A,B,C$相互对立。

事件独立性的概念可以推广到任意有限对个事件的情况。

**定义**：设$A_1,A_2,\cdots,A_n$是$n$个事件，若对任意的$m (2\le m\le n)$及任意的$1\le i_1<\cdots<i_m\le n$，若
$$
P(A_{i_1}A_{i_2}\cdots A_{i_m})=P(A_{i_1})P(A_{i_2})\cdots P(A_{i_m})
$$
则称事件$A_1,A_2,\cdots,A_n$相互独立。易见，上式包含$C_n^2+C_n^3+\cdots+C_n^n=2^n-n-1$个式子，要定义$n$个事件的独立性，这些等式都是必须的。

若$A_1,A_2,\cdots,A_n$相互独立，则$A_1,A_2,\cdots,A_n$必两两独立；反之若$A_1,A_2,\cdots,A_n$两两独立，则$A_1,A_2,\cdots,A_n$不一定相互独立。若$n$个事件$A_1,A_2,\cdots,A_n$相互独立，则它们的部分事件也是相互独立的。

计算相互独立的事件的概率时，常见事件之间的“并”、“差”等运算转化成“交”来计算，这常常会使计算上更为方便。例如事件$A$与事件$B$独立，则有：
$$
\begin{align}
P(A\cup B)&=1-P(\overline{A}\overline{B})=1-P(\overline{A})P(\overline{B}) \\
P(A-B)&=P(A\overline{B})=P(A)P(\overline{B})
\end{align}
$$


# 二、随机变量及其分布

## （一）分布函数

### 1. 分布函数的定义

设$X$为随机变量，称一元函数
$$
F(x)=P(X\le x) \qquad -\infty<x<+\infty
$$
为随机变量$X$的分布函数。可以看做随机点$X$落在半无穷区间$(-\infty,x]$内的概率。

### 2. 分布函数的性质

1. **单调性**，对于任意实数$a<b$，有$F(a)≤F(b)$
2. **规范性**，$F(-\infty)=\lim_\limits{x\rightarrow-\infty}F(x)=0$，$F(+\infty)=\lim\limits_{x\rightarrow+\infty}F(x)=1$
3. **右连续性**，对于任意实数$x$，$F(x^+)=\lim\limits_{t\rightarrow x^+}F(t)=F(x)$

### 3. 推论

单点概率为$P(X=a)=F(a)-F(a^-)$。

设$F(x)$是随机变量$X$的分布函数，$a<b$是任意实数，则
$$
\begin{align}
& P(X\le a)=F(a) \\
& P(X<a)=F(a^-) \\
& P(X>a)=1-F(a) \\
& P(X\ge a)=1-F(a^-) \\
& P(a<X\le b)=F(b)-F(a) \\
& P(a\le X\le b)=F(b)-F(a^-) \\
& P(a<X<b)=F(b^-)-F(a) \\
& P(a\le X<b)=F(b^-)-F(a^-)
\end{align}
$$

## （二）离散型和连续型

### 1. 离散型随机变量及其分布列

若X为离散型随机变量，设$X$所有可能值为$x_1,x_1,\cdots,x_i,\cdots$，则称
$$
P(X=x_i)=p_i \qquad i=1,2,...
$$
为随机变量$X$的分布列（或概率分布）。

根据概率的可加性可求得$X$取值于任一集合$B$的概率$P(X\in B)=\sum\limits_{x_i\in B}P(X=x_i)$，令$B=(-\infty,x]$，就得到根据离散型随机变量X的分布列计算其分布函数的公式：
$$
F(x)=P(X\le x)=\sum_{x_i\le x}p_i
$$

### 2. 连续型随机变量及其密度函数

设随机变量$X$的分布函数为$F(x)$，如果存在非负可积函数$f(x)$，使得对于任一实数$x$，都有
$$
F(x)=\int_{-\infty}^xf(u)du
$$
则称$X$为连续型随机变量，而称$f(x)$为$X$的概率密度函数，简称密度函数。

上述定义实质上是说，对于任何连续型随机变量，都存在密度函数；反之，若一个随机变量存在密度函数，则这个随机变量一定是连续型随机变量。

根据微积分理论，若在点$x$处，密度函数$f(x)$连续，则
$$
f(x)=\frac{dF(x)}{dx}
$$
对于$X$在区间$(a, b]$上的概率，有
$$
P(a<X\le b)=F(b)-F(a)=\int_{-\infty}^bf(u)du-\int_{-\infty}^af(u)du=\int_a^bf(u)du
$$
这说明随机变量$X$在区间$(a, b]$内取值的概率恰好等于其密度函数在该区间上的定积分。

连续型随机变量的分布函数是$(-\infty, +\infty)$上的连续函数，对于任意实数$x$，有
$$
F(x)-F(x^-)=P(X=x)=0
$$
即连续型随机变量的单点概率为0。它揭示出连续型随机变量与离散性随机变量的本质的区别，即连续型随机变量取任一指定值的概率等于零，而离散型随机变量取某一指定值的概率可以大于零；由此可以看出，概率为0的事件未必是不可能事件，同样，概率为1的事件也未必是必然事件。

## （三）随机变量函数的分布

### 1. 离散型随机变量函数的分布

设$X$为离散型随机变量，而$Y=g(X)$，易见$Y$也是离散型随机变量，且$Y$的取值为$g(x_i),\ i=1,2,\cdots$，对于$Y$的每个可能值$y_j,\ j=1,2,\cdots$，确定相应的$C_j={x_i|g(x_i)=y_j}$，于是有$Y$的分布列
$$
P(Y=y_j)=P(X\in C_j)=q_j \qquad j=1,2,...
$$
直观上很明显，既然$x_i\in C_j$时，$g(x_i)$的值都等于$y_j$，自然把$X$在这些$x_i$处的概率合并为$Y=y_j$的概率。

### 2. 连续型随机变量函数的分布

1. **函数$g(x)$单调且其反函数存在连续导数**

设随机变量$X$的密度函数为$f_X(x)$，且有$P(X\in (a,b))=1$，$y=g(x)$在$(a,b)$上单调且其反函数存在连续导数，则随机变量$Y=g(X)$的密度函数为
$$
f_Y(y)=\begin{cases} f_X(h(y))\cdot|h^{'}(y)| & \alpha<y<\beta \\
0 & 其他
\end{cases}
$$
其中$x=h(y)$是$y=g(x)$在区间$(a,b)$上的反函数，且$\alpha=\min\{g(a),g(b)\},\beta=\max\{g(a),g(b)\}$。

2. **一般情况**

设随机变量$Y=g(X)$，其中$g(x)$是一元函数，记$C_y={x|g(x)\le y}$，为求随机变量$Y$的分布，首先计算$Y$的分布函数
$$
F_Y(y)=P(Y\le y)=P(g(X)\le y)=P(X\in C_y)=F_X(x)|_{x\in C_y}=\int_{C_y}f(x)dx
$$
如果$Y$存在密度函数，则可以通过对$F_Y(y)$求导得到$Y$的密度函数。这就是所谓的分布函数法。

# 三、多维随机变量及其分布

## （一）二维随机变量

### 1. 分布函数的定义

设$(X,Y)$是二维随机变量，对任意实数$x,y$，称二元函数
$$
F(x,y)=P(X\le x,Y\le y)
$$
为二维随机变量$(X,Y)$的分布函数，或随机变量$X$与$Y$的联合分布函数。

如果将二维随机变量$(X,Y)$看成平面上随机点的坐标，则分布函数$F(x,y)$在点$(x,y)$处的函数值就是随机点$(X,Y)$落在以$(x,y)$为顶点的左下方无限矩形区域内的概率。

### 2. 分布函数的性质

设$F(x,y)$是二位随机向量$(X,Y)$的分布函数，则有

1. **单调性**，关于$x$或$y$都是单调非降的。
2. **规范性**，$\begin{cases}
   F(x,-\infty)=\lim\limits_{y\to-\infty}(x,y)=0 \\
   F(-\infty,y)=\lim\limits_{x\to-\infty}(x,y)=0 \\
   F(-\infty,-\infty)=\lim\limits_{x,y\to-\infty}(x,y)=0 \\
   F(+\infty,+\infty)=\lim\limits_{x,y\to+\infty}(x,y)=1
   \end{cases}$
3. **右连续**，关于$x$或$y$都是右连续的，即$F(x^+,y)=F(x,y)\ ,\ F(x,y^+)=F(x,y)$
4. **相容性**，对于任意的$x_1<x_2，y_1<y_2$，有$F(x_2,y_2)-F(x_2,y_1)-F(x_1,y_2)+F(x_1,y_1)\ge0$

### 3. 离散型二维向量及其分布列

若二维随机变量$(X,Y)$只取有限对或可列对实数值$(x_i,y_j),\ i,j=1,2,\cdots$，则称$(X,Y)$为二维离散型随机变量，而称
$$
P(X=x_i,Y=y_j)=p_{ij} \qquad i,j=1,2,...
$$
为二维随机变量$(X,Y)$的分布列（或概率分布），或随机变量$X$与$Y$的联合分布列（或联合概率分布）。

二维向量$(X,Y)$落入二维区域$G$内的概率为$P((X,Y)\in G)=\sum\limits_{(x_i,y_j)\in G}p_{ij}$，而$(X,Y)$的联合分布函数为
$$
F(x,y)=P(X\le x,Y\le y)=\sum_{x_i\le x}\sum_{y_j\le y}p_{ij}
$$

### 4. 连续型二维向量及其分密度函数

设二维随机变量$(X,Y)$的联合分布函数为$F(x,y)$，若存在非负可积的二元函数$f(x,y)$，使得对于任意实数$x,y$，有
$$
F(x,y)=\int_{-\infty}^x\int_{-\infty}^yf(u,v)dudv
$$
则称$(X,Y)$为二维随机变量，而称二元函数$f(x,y)$为二维随机变量$(X,Y)$的概率密度函数（简称为密度函数），或称为$X$与$Y$的联合密度函数（简称联合密度函数）。

根据微积分理论，如果密度函数$f(x,y)$连续，则
$$
f(x,y)=\frac{\partial^{2}F(x,y)}{\partial x\partial y}
$$
对于二维向量$(X,Y)$落在平面上矩形区域$D={(x,y)|x_1<x\le x_2, y_1<y\le y_2}$内的概率为
$$
P(x_1<X\le x_2,y_1<Y\le y_2)=\iint\limits_{G}f(x,y)dxdy=\int_{x_1}^{x_2}\int_{y_1}^{y_2}f(x,y)dxdy
$$

## （二）边缘分布

### 1. 二维随机变量的边际分布函数

设二维随机变量$(X,Y)$的联合分布函数为$F(x,y)$，$(X,Y)$的两个边际分布函数，即$X$和$Y$的分布函数分别用$F_X(x),F_Y(y)$表示，有
$$
F_X(x)=P(X\le x)=P(X\le x,Y<+\infty)=\lim_{y\to+\infty}F(x,y)=F(x,+\infty) \\
F_Y(y)=P(Y\le y)=P(X<+\infty,Y\le y)=\lim_{x\to+\infty}F(x,y)=F(+\infty,y)
$$

### 2. 二维离散型随机变量的边际分布列

设二维随机变量$(X,Y)$的联合分布列为
$$
P(X=x_i,Y=y_j)=p_{ij} \qquad i,j=1,2,...
$$

则其关于$X$的边际分布列，将$x$固定，$y$取遍范围，因为互不相容，故可将所有$y$相加，得$X$的分布列为
$$
P(X=x_i)=\sum_{j=1}^{\infty}P(X=x_i,Y=y_j)=\sum_{j=1}^{\infty}p_{ij}=p_{i\cdot}
$$
同理可得$Y$的分布列为
$$
P(Y=y_i)=\sum_{i=1}^{\infty}P(X=x_i,Y=y_j)=\sum_{i=1}^{\infty}p_{ij}=p_{\cdot j}
$$

### 3. 二维连续型随机变量的边际密度函数

设二维连续型随机变量$(X,Y)$的联合分布函数为$F(x,y)$，联合密度函数为$f(x,y)$，则有$(X,Y)$关于$X$和关于$Y$的边际分布函数为
$$
F_X(x)=F(x,+\infty)=\int_{-\infty}^x\int_{-\infty}^{+\infty}f(u,v)dudv=\int_{-\infty}^x\left(\int_{-\infty}^{+\infty}f(u,v)dv\right)du \\
F_Y(y)=F(+\infty,y)=\int_{-\infty}^{+\infty}\int_{-\infty}^yf(u,v)dudv=\int_{-\infty}^y\left(\int_{-\infty}^{+\infty}f(u,v)du\right)dv
$$
关于$X$和关于$Y$的边际密度函数为
$$
f_X(x)=\int_{-\infty}^{+\infty}f(x,y)dy \\
f_Y(y)=\int_{-\infty}^{+\infty}f(x,y)dx
$$

## （三）条件分布

### 1. 离散型随机变量的条件概率分布

对于某个$i$，有$p_i=P(X=x_i)>0$，则有
$$
P(Y=y_j|X=x_i)=\frac{P(X=x_i,Y=y_j)}{P(X=x_i)}=\frac{p_{ij}}{p_{i\cdot}}
$$
是一个分布列，称其为$X=x_i$条件下，$Y$的条件分布列，或简称为$Y$关于$X=x_i$的条件分布列。

同理，$p_j=P(Y=y_j)>0$时，$X$关于$Y=y_j$的条件分布列为
$$
P(X=x_i|Y=y_j)=\frac{P(X=x_i,Y=y_j)}{P(Y=y_j)}=\frac{p_{ij}}{p_{\cdot j}}
$$

### 2. 连续型随机变量的条件分布

给定二维随机变量$X$和$Y$，对于实数轴上的任意集合$C$（一般为区间），如果$P(X\in C)>0$，则依据条件概率公式有
$$
P(Y\le y|X\in C)=\frac{P(X\in C,Y\le y)}{P(X\in C)}
$$
称其在条件$X\in C$的条件下，$Y$的条件分布函数，或简称为$Y$关于${X\in C}$的条件分布函数。连续型随机变量在单点处的概率为0。

特别地，对于二维随机变量$(X,Y)$有连续（或分段连续）的密度函数$f(x,y)$时，根据由极限的定义导出
$$
P(Y\le y|X=x)=\int_{-\infty}^y\frac{f(x,y)}{f_X(x)}dv
$$
由上面的式子表明，当$f_X(x)>0$时，变量$Y$关于$X=x$的条件密度函数$f_{Y|X}(y|x)$存在，且
$$
f_{Y|X}(y|x)=\frac{f(x,y)}{f_X(x)}
$$
当$f_Y(y)>0$时，变量$X$关于$Y=y$的条件密度函数$f_{X|Y}(x|y)$存在，且
$$
f_{X|Y}(x|y)=\frac{f(x,y)}{f_Y(y)}
$$
条件分布函数也是条件密度函数的变上限积分，即
$$
F_{Y|X}(y|x)=\int_{-\infty}^yf_{Y|X}(v|x)dv \\
F_{X|Y}(x|y)=\int_{-\infty}^xf_{X|Y}(u|y)du
$$

## （四）随机变量的独立性

### 1. 两个随机变量的独立性

**定义**：设$F(x,y)$是随机变量$(X,Y)$的联合分布函数，$F_X(x),F_Y(y)$分别是$(X,Y)$关于$X,Y$边际分布函数，如果对任意实数$x,y$，有
$$
F(x,y)=F_X(x)\cdot F_Y(y)
$$
则称随机变量$X$与$Y$相互独立，简称$X$与$Y$独立。

**定理**：离散型随机变量$X$与$Y$相互独立的充要条件是对任意$(X,Y)$的一切可能值$(x_i,y_j)$，都有$P(X=x_i,Y=y_j)=P(X=x_i)\cdot P(Y=y_j)$，即$p_{ij}=p_{i\cdot}p_{\cdot j}$

**定理**：设$(X,Y)$是连续型随机变量，$f_X(x),f_Y(y)$分别是$(X,Y)$关于$X,Y$边际密度函数，则$X$与$Y$相互独立的充要条件是$f(x,y)=f_X(x)\cdot f_Y(y)$，即$f_X(x)\times f_Y(y)$的值是其联合密度函数。

### 2. 多个随机变量的独立性

**定义**：设随机向量$(X_1,X_2,\cdots,X_n)$的联合分布函数为$F(x_1,x_2,\cdots,x_n)$，关于$X_1,X_2,\cdots,X_n$的边际分布函数分别是$F_1(x_1),F_2(x_2),\cdots,F_n(x_n)$，如果对于任意一组实数$x_1,x_2,\cdots,x_n$，有$F(x_1,x_2,\dots,x_n)=F_1(x_1)F_2(x_2)\cdots F_n(x_n)$，则称随机变量$X_1,X_2,\cdots,X_n$相互独立。

**定理**：离散型随机向量$X_1,X_2,\cdots,X_n$相互独立的充要条件是对于任意一组实数$x_1,x_2,\cdots,x_n$，有$P(X_1=x_1,X_2=x_2,\dots,X_n=x_n)=P(X_1=x_1)P(X_2=x_2)\cdots P(X_n=x_n)$

**定理**：连续型随机向量$X_1,X_2,\cdots,X_n$，设它们的密度函数是$f_1(x_1),f_2(x_2),\cdots,f_n(x_n)$，则相互独立的充要条件是对于任意一组实数$x_1,x_2,\cdots,x_n$，有$f(x_1,x_2,\dots,x_n)=f_1(x_1)f_2(x_2)\cdots f_n(x_n)$

**定义**：设$m$维随机向量$(X_1,X_2,\cdots,X_m)$和$n$维随机向量$(Y_1,Y_2,\cdots,Y_n)$，以及$m+n$维随机向量$(X_1,X_2,\cdots,X_m;Y_1,Y_2,\cdots,Y_n)$，如果有$F(x_1,x_2,\dots,x_m;y_1,y_2,\dots,y_n)=F_1(x_1,x_2,\dots,x_m)\cdot F_2(y_1,y_2,\dots,y_n)$，则称随机向量$(X_1,X_2,\cdots,X_m)$和$(Y_1,Y_2,\cdots,Y_n)$相互独立。

**定理**：如果随机向量$(X_1,X_2,\cdots,X_m)$和$(Y_1,Y_2,\cdots,Y_n)$相互独立，且$X_1,X_2,\cdots,X_m$相互独立，$Y_1,Y_2,\cdots,Y_n$也相互独立，则$X_1,X_2,\cdots,X_m;Y_1,Y_2,\cdots,Y_n$相互独立。

**定理**：设随机向量$X_1,X_2,\cdots,X_m$是相互独立的，则有

1. **部分独立性**，它们的任一部分也是相互独立的。
2. **函数独立性**，它们的函数$g_1(x_1),g_2(x_2),\cdots,g_n(x_n)$也是相互独立的，其中$g_i$是任意的一元函数。

## （五）多维随机变量函数的分布

主要以二维情形为例展开讨论，并主要讨论连续型情况。

设二维连续型随机变量$(X,Y)$的密度函数为$f(x,y)$，而随机变量$Z=g(X,Y)$，其中$g(x,y)$是二元函数。为求随机变量$Z$的分布，可以采用一般方法：
$$
F_Z(z)=P(Z\le z)=P(g(X,Y)\le z)=P((X,Y)\in D_z)=F(x,y)|_{(x,y)\in D_z}=\iint_{D_z}f(x,y)dxdy
$$
其中$D_z={(x,y)|g(x,y)\le z}$。当$Z$存在密度函数时，可以通过对$F_Z(z)$求导得$Z$的密度函数。

**和的分布**，设二维连续型随机变量$(X,Y)$的密度函数为$f(x,y)$，而随机变量$Z=X+Y$，它的分布函数可表示为
$$
F_Z(z)=P(Z\le z)=P(X+Y\le z)=\iint_{x+y\le z}f(x,y)dxdy \\
=\int_{-\infty}^{+\infty}dx\int_{-\infty}^{z-x}f(x,y)dy=\int_{-\infty}^{+\infty}dy\int_{-\infty}^{z-y}f(x,y)dx
$$
则，求$F_Z(z)$对$z$的导数（将$x$和$y$看成参数），即得随机变量$Z=X+Y$的密度公式为
$$
f_Z(z)=\int_{-\infty}^{+\infty}f(x,z-x)dx=\int_{-\infty}^{+\infty}f(z-y,y)dy
$$
当$X$与$Y$独立式，可得公式（卷积公式）：
$$
f_Z(z)=\int_{-\infty}^{+\infty}f_X(x)f_Y(z-x)dx=\int_{-\infty}^{+\infty}f_X(z-y)f_Y(y)dy
$$
其中$f_X(x),f_Y(y)$分别是$X,Y$的边际密度函数。

**商的分布**，设二维连续型随机变量$(X,Y)$的密度函数为$f(x,y)$，而随机变量$Z=X/Y$，则$Z$的密度函数公式为$f_Z(z)=\int_{-\infty}^{+\infty}f(zy,y)|y|dy$

**极大值与极小值分布**，设随机变量$X_1,X_2,\cdots,X_n$相互独立，$X_i\sim F_i(x)$，记$X=\max(X_1,X_2,\cdots,X_n),Y=\min(X_1,X_2,\cdots,X_n)$，则
$$
\begin{align}
& F_X(x)=F_1(x)F_2(x)\cdots F_n(x) \\
& F_Y(x)=1-[1-F_1(x)][1-F_2(x)]\cdots [1-F_n(x)]
\end{align}
$$
特别地，当$X_1,X_2,\cdots,X_n$具有相同的分布函数$F(x)$时，即独立同分布时，有
$$
\begin{align}
& F_X(x)=[F(x)]^n \\
& F_Y(x)=1-[1-F(x)]^n
\end{align}
$$

# 四、随机变量的数字特征

## （一）期望

### 1. 期望的定义

设离散型随机变量$X$，若级数$\sum\limits_{i=1}^\infty x_ip_i$绝对收敛，则称其和为随机变量$X$（或其分布）的数学期望，简称为期望或均值，即
$$
E[X]=\sum_{i=1}^\infty x_ip_i
$$
当它非绝对收敛时，随机变量$X$的数学期望不存在。

设连续型随机变量$X$的密度函数为$f(x)$，若积分$\int_{-\infty}^{+\infty}xf(x)dx$绝对收敛，则称其为$X$（或其分布）的数学期望，简称为期望或均值，即
$$
E[X]=\int_{-\infty}^{+\infty}xf(x)dx
$$

### 2. 随机变量函数的数学期望

设$Y=g(X)$，其中$X$为随机变量，$g(x)$为连续函数，则离散型和连续型随机变量函数的数学期望为
$$
E[Y]=E[g(X)]=\sum_{i=1}^\infty g(x_i)p_i \\
E[Y]=E[g(X)]=\int_{-\infty}^{+\infty} g(x)f(x)dx
$$
设$Z=g(X,Y)$为二维连续函数，则离散型和连续型随机变量函数的数学期望为
$$
E[Z]=E[g(X,Y)]=\sum_{i=1}^\infty\sum_{j=1}^\infty g(x_i,y_j)p_{ij} \\
E[Z]=E[g(X,Y)]=\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty} g(x,y)f(x,y)dxdy
$$
特别地，当$(X,Y)$是连续型随机变量时，$X,Y$的数学期望分别为
$$
E[X]=\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty} xf(x,y)dxdy \\
E[Y]=\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty} yf(x,y)dxdy
$$

### 3. 数学期望的性质

设$X,Y$为随机变量，且$E[X],E[Y]$存在，设$C,a,b$为任意常数。

1. $E[C]=C$
2. $E[aX+bY]=aE[X]+bE[Y]$；特别地，$E[aX]=aE[X]$，$E[X+Y]=E[X]+E[Y]$
3. 若$X,Y$相互独立，则有$E[XY]=E[X]E[Y]$
   - 实际上$E[XY]=E[X]E[Y]$的充要条件可以减弱到$X$与$Y$不相关即可。
4. 若$X\ge 0$，则有$E[X]\ge0$；若$X\le Y$，则有$E[X]\le E[Y]$
5. $|E[X]|\le E[|X|]$

### 4. 示性变量

设$A$为随机事件，由事件$A$定义的取值为0或1的二值变量
$$
I_A(\omega)=\begin{cases}
1 & \omega \in A \\
0 & \omega \notin A
\end{cases}
$$
称为事件$A$的示性变量，简记为$I_A$

由于$P(I_A=1)=P(A)$，故事件$A$的示性变量$I_A$的数学期望等于事件$A$的概率，即$E[I_A]=P(A)$。

## （二）方差

### 1. 方差的定义

设$X$为随机变量，若$E[(X-E[X])^2]$存在，则称它为随机变量$X$的方差，记为$D[X]$，即
$$
D[X]=E[(X-E[X])^2]=E[X^2]-E^2[X]=E[X(X-1)]+E[X]-E^2[X]
$$

它得开根号$\sqrt{D[X]}$称为随机变量$X$的标准差或均方差。

### 2. 方差的性质

设$X,Y$为随机变量，设$C,d$为任意常数。

1. $D[X]=E[X^2]-E^2[X]\ge0$，取等号的充要条件为：$X$只取一个常数$C$。
2. $D[CX+d]=C^2D[X]$
3. $D[X\pm Y]=D[X]+D[Y]\pm2E[(X-E[X])(Y-E[Y])]=D[X]+D[Y]\pm2cov(X,Y)$，这可以推广到多个随机变量，类似于多项式的平方展开。
   - 特别地当$X,Y$独立时，$D[X\pm Y]=D[X]+D[Y]$，实际上它成立的充要条件可以减弱到$X$与$Y$不相关即可。
4. 任意$C\ne EX$，有$D[X]=E[(X-E[X])^2]<E[(X-C)^2]$

### 3. 方差标准化

方差有单位，值的大小会收单位影响，标准化后不收单位影响。设$X$为随机变量，期望$E[X]$和方差$D[X]$存在，令
$$
X^*=\frac{X-E[X]}{\sqrt{D[X]}}
$$
称$X^*$为$X$的标准化，易见$E[X^*]=0,D[X^*]=1$。

## （三）协方差、相关系数

### 1. 协方差的定义

设$X,Y$为随机变量，若$E[(X-E[X])(Y-E[Y])]$存在，则称其为随机变量$X$与$Y$的协方差，即
$$
cov(X,Y)=E[(X-E[X])(Y-E[Y])]=E[XY]-E[X]E[Y]
$$
特别地有$cov(X,X)=D[X]$，即随机变量自己的协方差就是方差。

### 2. 协方差的性质

设$X,Y$是随机变量。这两条性质需要假定右边出现的协方差均存在，可以简洁地表述为，协方差是对称双线性（二元）函数。第三条不是性质，但为了记录方便，放在此处。

1. $cov(X,Y)=cov(Y,X)$
2. $cov(aX_1+bX_2,Y)=a\cdot cov(X_1,Y)+b\cdot cov(X_2,Y)$；可以推广到任意有限个随机变量的情形，即双线性性质，$cov(\sum\limits_{i=1}^ma_iX_i,\sum\limits_{j=1}^nb_jY_j)=\sum\limits_{i=1}^m\sum\limits_{j=1}^na_ib_jcov(X_i,Y_j)$
3. 若$X,Y$独立，则$cov(X,Y)=0$，特别地对任意常数$C$，有$cov(X,C)=0$

### 3. 相关系数

为了消除计量单位的影响，对$X,Y$分别施行标准化得$X^*,Y^*$，然后再求协方差。若$D[X],D[Y]>0$，称
$$
\rho_{XY}=cov(X^*,Y^*)=cov(\frac{X-E[X]}{\sqrt{D[X]}},\frac{Y-E[Y]}{\sqrt{D[Y]}})=\frac{cov(X,Y)}{\sqrt{D[X]}\sqrt{D[Y]}}
$$
为随机变量$X$和$Y$的相关系数，在不会混淆时，可简记为$\rho$。

若随机变量$X$与$Y$的相关系数$\rho$存在，则$|\rho|\le 1$；取等号的充要条件是存在$a\ne 0$及$b$，使得$P(Y=aX+b)=1$。

### 4. 独立与不相关

若随机变量$X$与$Y$的相关系数$\rho$存在，则

1. 如果$\rho=0$，则称$X$与$Y$不相关；否则，称$X$与$Y$相关。
2. 如果$\rho>0$，则称$X$与$Y$正相关；其中当$\rho=1$时，称为完全正相关。
3. 如果$\rho<0$，则称$X$与$Y$负相关；其中当$\rho=-1$时，称为完全负相关。

如果$X,Y$独立，则$X,Y$一定不相关；若$X,Y$不相关，则$X,Y$不一定独立。特别地对于二维正态分布$(X,Y)\sim N(\mu_1,\mu_2,\sigma_1,\sigma_2,\rho)$，若$X,Y$不相关，则$X,Y$独立，即二维正态分布的不相关与独立等价。

## （四）随机变量的矩

设随机变量$X,Y$，正整数$k,l$，有如下

原点矩：$\alpha_k=E[X^k]$，绝对原点矩：$\beta_k=E[|X|^k]$，混合原点矩：$E[X^kY^l]$

中心矩：$\mu_k=E[(X-E[X])^k]$，绝对中心矩：$v_k=E[|X-E[X]|^k]$，混合中心矩：$E[(X-E[X])^k(Y-E[Y])^l]$

显然，随机变量$X$的一阶原点矩就是期望，$X$的二阶中心矩就是方差，$X$和$Y$的二阶混合中心矩就是协方差

# 五、大数定律与极限定理

## （一）大数定律

### 1. 引理

1. **切比雪夫不等式**

随机变量$X$的期望和方差存在，对任意$\varepsilon>0$，有
$$
P(|X-E[X]|\ge\varepsilon)\le\frac{D[X]}{\varepsilon^2}
$$
即$X$偏离$E[X]$超过$\varepsilon$的概率不大于右侧。

2. **依概率收敛**

设$Y_1,Y_2,\cdots,Y_n,\cdots$是随机变量列，$Y$是一个随机变量，如果对任意$\varepsilon>0$，有
$$
\lim_{n\rightarrow\infty}P\{|Y_n-Y|\ge\varepsilon\}=0
$$
则称随机变量列$Y_1,Y_2,\cdots,Y_n,\cdots$**依概率收敛**于随机变量$Y$，记为$Y_n\stackrel{P}{\longrightarrow} Y$。随机变量列$Y_1,Y_2,\cdots,Y_n,\cdots$可简记为$\{Y_n\}^{\infty}_{n=1}$或$\{Y_n\}$。

特别地，若随机变量$Y$是一个常数，即随机变量列$\{Y_n\}$依概率收敛于某个常数$C$，则表示当$n$充分大时，随机变量$Y_n$几乎失去了随机性，其值越来越接近于常数$C$；或者说随着$n$增大，$Y_n$稳定于常数$C$。

3. **大数定律**

设$X_1,X_2,\cdots,X_n,\cdots$是随机变量列，$S=X_1+X_2+\cdots+X_n$，记$\bar{X}_n=S_n/n$，若存在数列$a_1,a_2,\cdots,a_n,\cdots$，使得对于任意$\varepsilon > 0$，有
$$
\lim_{n\rightarrow\infty}P\{|\bar{X}_n-a_n|\ge\varepsilon\}=0
$$
即$\bar{X}_n-a_n\stackrel{P}{\longrightarrow}0$，则称$\{X_n\}$服从大数定律。等价的定义是$\lim\limits_{n\rightarrow\infty}P\{|\bar{X}_n-a_n|<\varepsilon\}=1$。

本书只研究$\{X_n\}$中的每一个随机变量的期望$E_n\ (n\ge 1)$均存在当情况，这时可将定义中常数列$\{a_n\}$可取为$\{E\bar{X}_n\}$，即对任意的$\varepsilon>0$，有$\bar{X}_n-E\bar{X}_n \stackrel{P}{\longrightarrow}0$。

根据随机变量列$\{X_n\}$所具有的性质不同，可得到不同形式的大数定律。

### 2. 切比雪夫大数定律

设随机变量列$\{X_n\}$相互独立（或两两不相关），且相应的方差序列$\{D[X_n]\}$有界，则$\{X_n\}$服从大数定律，即对任意的$\varepsilon>0$，有
$$
\lim_{n\rightarrow\infty}P\{|\bar{X}_n-E\bar{X}_n|\ge\varepsilon\}=0
$$
成立。

### 3. 辛钦大数定律

设$\{X_n\}$为独立同分布的随机变量列，且具有有限的数学期望$\mu=E[X_i],i=1,2,\cdots$，则$\{X_n\}$服从大数定律，即对任意的$\varepsilon>0$，有
$$
\lim_{n\rightarrow\infty}P\{|\bar{X}_n-\mu|\ge\varepsilon\}=0
$$
成立。

### 4. 伯努利大数定律

设$\mu_n\sim B(n,p)$，即随机变量$\mu_n$为$n$重伯努利实验中事件$A$出现的次数，而$p\ (0<p<1)$为每次试验事件$A$出现的概率，则对任意的$\varepsilon>0$，有
$$
\lim_{n\rightarrow\infty}P\{|\frac{\mu_n}{n}-p|\ge\varepsilon\}=0
$$
成立。

伯努利大数定律表明，当在条件不变的情况下独立地进行多次试验（即独立重复试验）时，随着试验次数的增大，随机事件$A$的频率将逐步趋于稳定，且频率的稳定中心即为事件$A$的概率。

**实际推断原理**指的是，发生的概率很小（通常取为$0.1,0.05,0.01$）的事件（简称为小概率事件）在个别试验中是不可能发生的。需要指出的是，任何有正概率的随机事件，无论其概率多么小，总是可能发生的，因此用实际推断原理作出的结论并不是完全可靠的。

## （二）中心极限定理

中心极限定理是概率论中有关论证“大量随机变量之和的极限分布是正态分布”的一系列定理的总称。许多情形下，一种随机现象可能受到多种不确定因素的影响，如果这些因素彼此没有依赖关系，且单个因素没有突出的影响，那么这些因素的总和效应将会使随机现象近似地服从正态分布，这正是中心极限定理所描述的统计规律。

### 1. 列维-林德伯格（独立同分布）

设$\{X_n\}$是独立同分布（简记为i.i.d）的随机变量列，且具有有限的期望与方差，即$E[X]=\mu,D[X]=\sigma^2,\ n=1,2,\cdots,$，记$S_n=X_1+X_2+\cdots+X_n$为$\{X_n\}$的部分和，则对任意实数$x$，有
$$
\lim_{n\rightarrow\infty}P(\frac{S_n-n\mu}{\sqrt{n}\sigma}\le x)=\Phi(x)
$$
其中$\Phi(x)$为标准正态分布函数。也可以对分子分母同时除以$n$，其等价为
$$
\lim_{n\rightarrow\infty}P(\sqrt{n}\frac{\bar{X}_n-\mu}{\sigma}\le x)=\Phi(x)
$$
在实际问题中，当$n$大于45时，就可以使用$\approx$来计算。

### 2. 棣莫弗-拉普拉斯（二项分布）

设$\mu_n\sim B(n,p)$，即随机变量$\mu_n$为$n$重伯努利试验中事件$A$发生的次数，每次试验事件$A$发生的概率为$p$，则对任意实数$x$，有
$$
\lim_{n\rightarrow\infty}P(\frac{\mu_n-np}{\sqrt{np(1-p)}}\le x)=\Phi(x)
$$
由此定理可知，正态分布是二项分布的极限分布。因此当$n$较大（超过$45$）时，可利用正态分布计算与二项分布有关的事件的概率，例如
$$
\begin{align}
P(m_1\le\mu_n\le m2) &= P(\frac{m_1-np}{\sqrt{np(1-p)}}\le\frac{\mu_n-np}{\sqrt{np(1-p)}}\le\frac{m_2-np}{\sqrt{np(1-p)}}) \\
&= \Phi(\frac{m_2-np}{\sqrt{np(1-p)}})-\Phi(\frac{m_1-np}{\sqrt{np(1-p)}})
\end{align}
$$
